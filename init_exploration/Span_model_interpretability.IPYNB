{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt: THIS MODEL IS ALREADY SAVED ON HUGGING FACE PLATFORM.\n",
    "# I AM MAKING FINANCIAL CHATBOAT IN WHICH WHEN USER UPLOADS ANY PDF FOR THE QUESTIONS. \n",
    "# THERE IS BERT MODEL WHICH GIVES OUTPUT THAT WHETHER THE QUESTION IS SPAN OR ARITHMETIC. \n",
    "# NOW I WANT TO INTERPRETATE THE BERT MODEL ON TEXT DATA ONLY IN WHICH I WANT CODE THAT INTERPRETATE THE MODEL USING LIME ALGORTIHTM WHICH GIVE INFORMATION OF OUTPUT THAT MODEL PERFORMS WELL AGAINST OUTPUT OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: 'What is the difference between 2019 average rate of inflation and 2019 average rate of increase in salaries?'\n",
      "Predicted: arithmetic (confidence: 99.93%)\n",
      "\n",
      "Top features influencing the prediction:\n",
      "average              +0.1809\n",
      "difference           +0.1228\n",
      "2019                 +0.0577\n",
      "between              +0.0473\n",
      "and                  +0.0448\n",
      "rate                 +0.0389\n",
      "of                   +0.0323\n",
      "is                   -0.0258\n",
      "increase             -0.0242\n",
      "in                   +0.0115\n",
      "\n",
      "Text highlighting:\n",
      "What is the [+0.12]difference between 2019 [+0.18]average rate of inflation and 2019 [+0.18]average rate of increase in salaries?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Question: 'How much was the closing net book amount for software under development in 2019?'\n",
      "Predicted: span (confidence: 98.56%)\n",
      "\n",
      "Top features influencing the prediction:\n",
      "was                  +0.0795\n",
      "much                 -0.0339\n",
      "How                  -0.0293\n",
      "the                  +0.0221\n",
      "for                  -0.0148\n",
      "software             -0.0138\n",
      "under                -0.0130\n",
      "amount               -0.0114\n",
      "net                  -0.0087\n",
      "development          -0.0086\n",
      "\n",
      "Text highlighting:\n",
      "How much was the closing net book amount for software under development in 2019?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Question: 'What was the percentage change in cost of software under development between 2018 and 2019?'\n",
      "Predicted: arithmetic (confidence: 99.86%)\n",
      "\n",
      "Top features influencing the prediction:\n",
      "percentage           +0.1852\n",
      "change               +0.1548\n",
      "and                  +0.1483\n",
      "between              +0.1235\n",
      "2018                 +0.0743\n",
      "was                  -0.0675\n",
      "2019                 +0.0650\n",
      "of                   +0.0593\n",
      "cost                 +0.0464\n",
      "under                +0.0361\n",
      "\n",
      "Text highlighting:\n",
      "What was the [+0.19]percentage [+0.15]change in cost of software under development [+0.12]between 2018 [+0.15]and 2019?\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import lime\n",
    "import lime.lime_text\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load your model and tokenizer\n",
    "model_name = \"rahul14/span-arithmetic-classification\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prediction function for LIME\n",
    "def predictor(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=32)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Create LIME explainer\n",
    "explainer = lime.lime_text.LimeTextExplainer(class_names=[\"arithmetic\", \"span\"])\n",
    "\n",
    "def interpret_question(question):\n",
    "    def highlight_text(words, explanation):\n",
    "        highlighted = []\n",
    "        for word in words:\n",
    "            weight = next((w for feature, w in explanation if feature.lower() in word.lower()), 0)\n",
    "            if weight > 0.1:\n",
    "                highlighted.append(f\"[+{weight:.2f}]{word}\")\n",
    "            elif weight < -0.1:\n",
    "                highlighted.append(f\"[{weight:.2f}]{word}\")\n",
    "            else:\n",
    "                highlighted.append(word)\n",
    "        return highlighted\n",
    "\n",
    "    try:\n",
    "        # Prediction\n",
    "        pred_probs = predictor([question])[0]\n",
    "        predicted_class = np.argmax(pred_probs)\n",
    "        confidence = pred_probs[predicted_class]\n",
    "        \n",
    "        print(f\"\\nQuestion: '{question}'\")\n",
    "        print(f\"Predicted: {'arithmetic' if predicted_class == 0 else 'span'} (confidence: {confidence:.2%})\")\n",
    "        \n",
    "        # Explanation\n",
    "        exp = explainer.explain_instance(question, predictor, num_features=10, num_samples=500, top_labels=1)\n",
    "        explanation = get_explanation(exp, predicted_class)\n",
    "        \n",
    "        print(\"\\nTop features influencing the prediction:\")\n",
    "        for feature, weight in explanation:\n",
    "            print(f\"{feature:20} {weight:+.4f}\")\n",
    "        \n",
    "        print(\"\\nText highlighting:\")\n",
    "        print(' '.join(highlight_text(question.split(), explanation)))\n",
    "        \n",
    "        return exp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error interpreting question: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_explanation(exp, predicted_class):\n",
    "    try:\n",
    "        return exp.as_list(label=predicted_class)\n",
    "    except KeyError:\n",
    "        return exp.as_list(label=0) if len(exp.available_labels()) > 0 else []\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sample_questions = [\n",
    "    # \"What is the difference between 2019 average rate of inflation and 2019 average rate of increase in salaries?\",\n",
    "    \"How much was the closing net book amount for software under development in 2019?\",\n",
    "    \"What was the percentage change in cost of software under development between 2018 and 2019?\"\n",
    "]\n",
    "\n",
    "for question in sample_questions:\n",
    "    _ = interpret_question(question)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File ~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lime\\explanation.py:141, in Explanation.as_list(self, label, **kwargs)\n",
    "    # 128 \"\"\"Returns the explanation as a list.\n",
    "    # 129 \n",
    "    # 130 Args:\n",
    "#    (...)    138     given by domain_mapper. Weight is a float.\n",
    "#     139 \"\"\"\n",
    "#     140 label_to_use = label if self.mode == \"classification\" else self.dummy_label\n",
    "# --> 141 ans = self.domain_mapper.map_exp_ids(self.local_exp[label_to_use], **kwargs)\n",
    "#     142 ans = [(x[0], float(x[1])) for x in ans]\n",
    "#     143 return ans\n",
    "\n",
    "# THIS IS MY CODE YOU PROVIDES AND THE KEY ERROR GOT FROM THR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prompt to chatgpt: I need a best model to classify whether the question is text or arithmetic\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'answer', 'answer_type', 'derivation'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Data/questions_table.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['multi-span', 'span', 'arithmetic', 'count'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"answer_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data[data[\"answer_type\"].isin([\"span\", \"arithmetic\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11265"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>derivation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much is the 2019 rate of inflation?</td>\n",
       "      <td>['2.9']</td>\n",
       "      <td>span</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much is the 2018 rate of inflation?</td>\n",
       "      <td>['2.9']</td>\n",
       "      <td>span</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the 2019 average rate of inflation?</td>\n",
       "      <td>2.9</td>\n",
       "      <td>arithmetic</td>\n",
       "      <td>(2.9+2.9)/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the 2019 average rate of increase in s...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>arithmetic</td>\n",
       "      <td>(2.7+2.7)/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the difference between 2019 average ra...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>arithmetic</td>\n",
       "      <td>[(2.9+2.9)/2] - [(2.7+2.7)/2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question   answer answer_type  \\\n",
       "1            How much is the 2019 rate of inflation?  ['2.9']        span   \n",
       "2            How much is the 2018 rate of inflation?  ['2.9']        span   \n",
       "3        What is the 2019 average rate of inflation?      2.9  arithmetic   \n",
       "4  What is the 2019 average rate of increase in s...      2.7  arithmetic   \n",
       "5  What is the difference between 2019 average ra...      0.2  arithmetic   \n",
       "\n",
       "                      derivation  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                    (2.9+2.9)/2  \n",
       "4                    (2.7+2.7)/2  \n",
       "5  [(2.9+2.9)/2] - [(2.7+2.7)/2]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_n = dataset[[\"question\", \"answer_type\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much is the 2019 rate of inflation?</td>\n",
       "      <td>span</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much is the 2018 rate of inflation?</td>\n",
       "      <td>span</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the 2019 average rate of inflation?</td>\n",
       "      <td>arithmetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the 2019 average rate of increase in s...</td>\n",
       "      <td>arithmetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the difference between 2019 average ra...</td>\n",
       "      <td>arithmetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer_type\n",
       "1            How much is the 2019 rate of inflation?        span\n",
       "2            How much is the 2018 rate of inflation?        span\n",
       "3        What is the 2019 average rate of inflation?  arithmetic\n",
       "4  What is the 2019 average rate of increase in s...  arithmetic\n",
       "5  What is the difference between 2019 average ra...  arithmetic"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset_n[\"question\"]\n",
    "y = dataset_n[\"answer_type\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What was the average settlements for 2017-2019?',\n",
       "       'What was the estimated useful life of Towers in years?',\n",
       "       'What is the average quarterly high sale price for 2019?',\n",
       "       'What does the table show?',\n",
       "       'What was the working capital in 2019?'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12630    arithmetic\n",
       "7307           span\n",
       "11472    arithmetic\n",
       "1573           span\n",
       "4538           span\n",
       "Name: answer_type, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_tfidf = vectorizer.fit_transform(X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_tfidf, y_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'What was the change in the Total non-current trade and other payables in 2019 from 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage increase / (decrease) in Fuel Oils from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the average hardware revenue from 2016 to 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage change in revenue generated from Partner C from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'As of March 29, 2019, What is Intangible assets expressed as a percentage of  Gross deferred tax assets?' --> Prediction: arithmetic --> True Label: arithmetic\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_tfidf)\n",
    "i = 0\n",
    "for text, pred, true_label in zip(X_test, predictions, y_test):\n",
    "    print(f\"Input: '{text}' --> Prediction: {pred} --> True Label: {true_label}\")\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt: How to save the vectorizer and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(data, file_name):\n",
    "    os.makedirs(\"../artifacts/model\", exist_ok = True)\n",
    "    try:\n",
    "        file_path = f\"../artifacts/model/{str(file_name)}.pkl\"\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "        print(f\"Data saved succesfully at: {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save model due to: {str(e)}\")\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved succesfully at: ../artifacts/model/vectorizer.pkl\n",
      "Data saved succesfully at: ../artifacts/model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model(data = vectorizer, file_name = \"vectorizer\")\n",
    "save_model(data = model, file_name = \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt: How to measure the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92403265885694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt: Other model approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'What was the change in the Total non-current trade and other payables in 2019 from 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage increase / (decrease) in Fuel Oils from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the average hardware revenue from 2016 to 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage change in revenue generated from Partner C from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'As of March 29, 2019, What is Intangible assets expressed as a percentage of  Gross deferred tax assets?' --> Prediction: arithmetic --> True Label: arithmetic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Split data into texts (X) and labels (y)\n",
    "X = dataset_n[\"question\"]\n",
    "y = dataset_n[\"answer_type\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "i = 0\n",
    "for text, pred, true_label in zip(X_test, predictions, y_test):\n",
    "    print(f\"Input: '{text}' --> Prediction: {pred} --> True Label: {true_label}\")\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8044378698224852\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'What was the change in the Total non-current trade and other payables in 2019 from 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage increase / (decrease) in Fuel Oils from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the average hardware revenue from 2016 to 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage change in revenue generated from Partner C from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'As of March 29, 2019, What is Intangible assets expressed as a percentage of  Gross deferred tax assets?' --> Prediction: arithmetic --> True Label: arithmetic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC  # Support Vector Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into texts (X) and labels (y)\n",
    "X = dataset_n[\"question\"]\n",
    "y = dataset_n[\"answer_type\"]\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "model = SVC(kernel='linear')  # Linear kernel for text classification\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "i = 0\n",
    "for text, pred, true_label in zip(X_test, predictions, y_test):\n",
    "    print(f\"Input: '{text}' --> Prediction: {pred} --> True Label: {true_label}\")\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9381656804733728\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt: Random forest classifier with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'What was the change in the Total non-current trade and other payables in 2019 from 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage increase / (decrease) in Fuel Oils from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the average hardware revenue from 2016 to 2018?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'What is the percentage change in revenue generated from Partner C from 2018 to 2019?' --> Prediction: arithmetic --> True Label: arithmetic\n",
      "Input: 'As of March 29, 2019, What is Intangible assets expressed as a percentage of  Gross deferred tax assets?' --> Prediction: arithmetic --> True Label: arithmetic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into texts (X) and labels (y)\n",
    "X = dataset_n[\"question\"]\n",
    "y = dataset_n[\"answer_type\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "i = 0\n",
    "for text, pred, true_label in zip(X_test, predictions, y_test):\n",
    "    print(f\"Input: '{text}' --> Prediction: {pred} --> True Label: {true_label}\")\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9491124260355029\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import logging\n",
    "# def save_model(data, file_name):\n",
    "#     os.makedirs(\"../artifacts/model\", exist_ok = True)\n",
    "#     try:\n",
    "#         file_path = f\"../artifacts/model/{str(file_name)}.pkl\"\n",
    "#         with open(file_path, \"wb\") as file:\n",
    "#             pickle.dump(data, file)\n",
    "#         print(f\"Data saved succesfully at: {file_path}\")\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Failed to save model due to: {str(e)}\")\n",
    "#         raise\n",
    "    \n",
    "# save_model(data = vectorizer, file_name = \"vectorizer_final\")\n",
    "# save_model(data = model, file_name = \"model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#NLP using tensorflow\n",
    "glove->embedding 6b,100d\n",
    "\n",
    "embedding tf.keras.layers.Embeddings\n",
    "transformers \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esrav\\FinChatbot\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7597 - loss: 0.4721 - val_accuracy: 0.9237 - val_loss: 0.2124\n",
      "Epoch 2/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9397 - loss: 0.1811 - val_accuracy: 0.9207 - val_loss: 0.2252\n",
      "Epoch 3/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9600 - loss: 0.1123 - val_accuracy: 0.9222 - val_loss: 0.2372\n",
      "Epoch 4/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9701 - loss: 0.0875 - val_accuracy: 0.9293 - val_loss: 0.2322\n",
      "Epoch 5/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0682 - val_accuracy: 0.9314 - val_loss: 0.2506\n",
      "Epoch 6/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0548 - val_accuracy: 0.9266 - val_loss: 0.2848\n",
      "Epoch 7/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9849 - loss: 0.0437 - val_accuracy: 0.9320 - val_loss: 0.3043\n",
      "Epoch 8/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0406 - val_accuracy: 0.9275 - val_loss: 0.3187\n",
      "Epoch 9/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0271 - val_accuracy: 0.9287 - val_loss: 0.3112\n",
      "Epoch 10/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0303 - val_accuracy: 0.9299 - val_loss: 0.3346\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.3241\n",
      "Test Accuracy: 0.9299\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Input: 'What was the change in the Total non-current trade and other payables in 2019 from 2018?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'What is the percentage increase / (decrease) in Fuel Oils from 2018 to 2019?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'What is the average hardware revenue from 2016 to 2018?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'What is the percentage change in revenue generated from Partner C from 2018 to 2019?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'As of March 29, 2019, What is Intangible assets expressed as a percentage of  Gross deferred tax assets?' --> Prediction: 1 --> True Label: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split data into texts (X) and labels (y)\n",
    "X = dataset_n[\"question\"]\n",
    "y = dataset_n[\"answer_type\"]\n",
    "\n",
    "# Encode labels as integers (if not already encoded)\n",
    "y = pd.factorize(y)[0]  # Factorize the labels into integer form\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)  # Limit to 5000 features\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert to dense format (TensorFlow prefers dense input)\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "# Convert labels to categorical (for multi-class classification)\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "# Build the NLP model in TensorFlow\n",
    "model = Sequential()\n",
    "\n",
    "# First layer (input layer)\n",
    "model.add(Dense(512, input_dim=X_train_tfidf.shape[1], activation='relu'))  # 512 neurons\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "# Second layer\n",
    "model.add(Dense(256, activation='relu'))  # 256 neurons\n",
    "model.add(Dropout(0.5))  # Dropout\n",
    "\n",
    "# Third layer\n",
    "model.add(Dense(128, activation='relu'))  # 128 neurons\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # Softmax for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_tfidf, y_train_cat, epochs=10, batch_size=32, validation_data=(X_test_tfidf, y_test_cat))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_tfidf, y_test_cat)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
    "\n",
    "# Print first 5 predictions\n",
    "i = 0\n",
    "for text, pred, true_label in zip(X_test, y_pred_classes, y_test):\n",
    "    print(f\"Input: '{text}' --> Prediction: {pred} --> True Label: {true_label}\")\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esrav\\FinChatbot\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.6930 - loss: 0.5918 - val_accuracy: 0.9169 - val_loss: 0.2378\n",
      "Epoch 2/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9285 - loss: 0.2026 - val_accuracy: 0.9325 - val_loss: 0.2040\n",
      "Epoch 3/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9527 - loss: 0.1529 - val_accuracy: 0.9340 - val_loss: 0.2031\n",
      "Epoch 4/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9581 - loss: 0.1225 - val_accuracy: 0.9320 - val_loss: 0.2093\n",
      "Epoch 5/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9626 - loss: 0.1115 - val_accuracy: 0.9311 - val_loss: 0.2167\n",
      "Epoch 6/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9695 - loss: 0.1032 - val_accuracy: 0.9287 - val_loss: 0.2367\n",
      "Epoch 7/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.0979 - val_accuracy: 0.9254 - val_loss: 0.2435\n",
      "Epoch 8/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9708 - loss: 0.0851 - val_accuracy: 0.9240 - val_loss: 0.2552\n",
      "Epoch 9/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9741 - loss: 0.0779 - val_accuracy: 0.9243 - val_loss: 0.2703\n",
      "Epoch 10/10\n",
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9716 - loss: 0.0825 - val_accuracy: 0.9251 - val_loss: 0.2906\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2711\n",
      "Test Accuracy: 0.9251\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Input: 'What was the change in the Total non-current trade and other payables in 2019 from 2018?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'What is the percentage increase / (decrease) in Fuel Oils from 2018 to 2019?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'What is the average hardware revenue from 2016 to 2018?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'What is the percentage change in revenue generated from Partner C from 2018 to 2019?' --> Prediction: 1 --> True Label: 1\n",
      "Input: 'As of March 29, 2019, What is Intangible assets expressed as a percentage of  Gross deferred tax assets?' --> Prediction: 1 --> True Label: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Split data into texts (X) and labels (y)\n",
    "X = dataset_n[\"question\"]\n",
    "y = dataset_n[\"answer_type\"]\n",
    "\n",
    "# Encode labels as integers (if not already encoded)\n",
    "y = pd.factorize(y)[0]  # Factorize the labels into integer form\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)  # Limit to 5000 features\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert to dense format (TensorFlow prefers dense input)\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "# Convert labels to categorical (for multi-class classification)\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "# Reshape to 3D for LSTM\n",
    "# TF-IDF data is 2D (samples, features), we need to reshape it to 3D (samples, timesteps, features)\n",
    "# Let's use the number of features as the timestep for each word's representation\n",
    "\n",
    "timesteps = 1  # We treat each word as a single timestep (each word gets a single feature vector)\n",
    "X_train_3d = X_train_tfidf.reshape((X_train_tfidf.shape[0], timesteps, X_train_tfidf.shape[1]))\n",
    "X_test_3d = X_test_tfidf.reshape((X_test_tfidf.shape[0], timesteps, X_test_tfidf.shape[1]))\n",
    "\n",
    "# Build the NLP model with LSTM in TensorFlow\n",
    "model = Sequential()\n",
    "\n",
    "# First layer (input layer)\n",
    "model.add(LSTM(128, input_shape=(X_train_3d.shape[1], X_train_3d.shape[2]), return_sequences=True))  # LSTM with 128 units\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "# LSTM Layer (the main addition)\n",
    "model.add(LSTM(64))  # LSTM with 64 units\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # Softmax for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_3d, y_train_cat, epochs=10, batch_size=32, validation_data=(X_test_3d, y_test_cat))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_3d, y_test_cat)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_3d)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Get the class with the highest probability\n",
    "\n",
    "# Print first 5 predictions\n",
    "i = 0\n",
    "for text, pred, true_label in zip(X_test, y_pred_classes, y_test):\n",
    "    print(f\"Input: '{text}' --> Prediction: {pred} --> True Label: {true_label}\")\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2074, Accuracy: 0.9153\n",
      "Test Accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample DataFrame (replace with actual dataset)\n",
    "dataset_n['answer_type'] = dataset_n['answer_type'].astype('category').cat.codes  # Label encoding\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset_n['question'].tolist(), dataset_n['answer_type'].tolist(), test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset class\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=32):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx], truncation=True, padding='max_length',\n",
    "            max_length=self.max_length, return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = QADataset(X_train, y_train, tokenizer)\n",
    "test_dataset = QADataset(X_test, y_test, tokenizer)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "num_labels = len(set(y_train))\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 1\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss, correct = 0, 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.logits.argmax(dim=-1) == labels).sum().item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/len(train_dataset):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_pred, y_true = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(**inputs)\n",
    "        y_pred.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the accuracy results as below:\n",
    "    Logistic regression with TF-IDF -> 92%\n",
    "    Naive Bayes with TF-IDF->  80%\n",
    "    SVC with TF-IDF->  93%\n",
    "    Random Forest Classifier with TF-IDF->  95%\n",
    "    NLP Model in tensor flow-> 92%\n",
    "    Added LSTM layer->92%\n",
    "    Prompt: make a new code using bert transformer using hugging face-> 96%\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

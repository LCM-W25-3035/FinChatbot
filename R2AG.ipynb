{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT first prompt :\n",
    "- \"i am building a RAG model using gpt-4o-mini as my generator. I want you to give me steps with code on how to incorporate R2AG into my RAG model. \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT last prompt :\n",
    "- \"i am getting the following error here : \n",
    "TypeError: 'ChatCompletionMessage' object is not subscriptable\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementaton :\n",
    "\n",
    "First, run the following command in the terminal to install langchain, transformers, faiss-cpu, and sentence-transformers for retrieval and embedding operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain transformers faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehaj\\OneDrive\\Desktop\\Capstone\\FinChatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import faiss\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.index = None  # FAISS Index\n",
    "\n",
    "    def build_index(self, documents):\n",
    "        embeddings = self.model.encode(documents, convert_to_numpy=True)\n",
    "        self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(embeddings)\n",
    "        self.docs = documents  # Storing original documents\n",
    "\n",
    "    def retrieve(self, query, top_k=3):\n",
    "        query_embedding = self.model.encode([query], convert_to_numpy=True)\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        return [self.docs[i] for i in indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Former(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(R2Former, self).__init__()\n",
    "        self.projection = torch.nn.Linear(input_dim, hidden_dim)  # Projection layer\n",
    "        self.self_attention = torch.nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=8)\n",
    "\n",
    "    def forward(self, retrieval_embeddings):\n",
    "        projected_embeddings = self.projection(retrieval_embeddings)\n",
    "        attn_output, _ = self.self_attention(projected_embeddings, projected_embeddings, projected_embeddings)\n",
    "        return attn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_retrievals(retriever, query, r2former):\n",
    "    retrieved_docs = retriever.retrieve(query)\n",
    "    embeddings = retriever.model.encode(retrieved_docs, convert_to_tensor=True)\n",
    "    embeddings = embeddings.unsqueeze(0)  # Reshaping for attention\n",
    "    refined_embeddings = r2former(embeddings)\n",
    "    return refined_embeddings, retrieved_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def generate_response(query, refined_embeddings, retrieved_docs):\n",
    "    retrieval_context = \" \".join(retrieved_docs)\n",
    "    r2ag_prompt = f\"Context: {retrieval_context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    \n",
    "    client = OpenAI() \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": r2ag_prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dog is a domesticated mammal belonging to the species Canis lupus familiaris. It is a subspecies of the gray wolf and has been bred over thousands of years for various traits, making it one of the most diverse species in terms of breeds. Dogs are known for their loyalty, companionship, and ability to perform various tasks, including herding, hunting, guarding, and providing assistance to humans. They often serve as pets and can form strong bonds with their owners, exhibiting a range of emotions and behaviors. Dogs communicate through vocalizations, body language, and facial expressions.\n"
     ]
    }
   ],
   "source": [
    "retriever = DocumentRetriever()\n",
    "retriever.build_index([\"Document 1 text...\", \"Document 2 text...\", \"Document 3 text...\"])  # Loading documents\n",
    "\n",
    "r2former = R2Former(input_dim=384, hidden_dim=768)  # Matching dimensions of LLM\n",
    "\n",
    "query = \"What is a dog?\"\n",
    "refined_embeddings, retrieved_docs = transform_retrievals(retriever, query, r2former)\n",
    "\n",
    "response = generate_response(query, refined_embeddings, retrieved_docs)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R2AG Evaluation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate this model, we will use the MuSiQue dataset using pandas which consists of questions with their ground truths/answers for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'musique_ans_v1.0_train.jsonl', 'validation': 'musique_ans_v1.0_dev.jsonl'}\n",
    "df = pd.read_json(\"hf://datasets/dgslibisey/MuSiQue/\" + splits[\"train\"], lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, we assume \"question\" and \"answer\" fields are strings\n",
    "df = df[[\"question\", \"answer\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT First Prompt :\n",
    "\n",
    "\"I want you to evaluate the above R2AG Model using the MuSiQue dataset i have imported in the code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT Last Prompt :\n",
    "\n",
    "\"the F1 score and Rouge scores for the above model are low in general, What steps can i take to improve these scores?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Preprocessing text data\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text (remove non-alphanumeric characters, lowercasing).\"\"\"\n",
    "    text = text.lower()\n",
    "    text = ''.join(e for e in text if e.isalnum() or e.isspace())  # Removing punctuation\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score Evaluation\n",
    "def f1_score_evaluation(predicted_answer, true_answer):\n",
    "    \"\"\"\n",
    "    Evaluate using F1 Score. This checks the precision and recall of exact matches.\n",
    "    \"\"\"\n",
    "    predicted_match = 1 if predicted_answer == true_answer else 0\n",
    "    true_match = 1\n",
    "    return predicted_match, true_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Evaluation\n",
    "def rouge_evaluation(predicted_answer, true_answer):\n",
    "    \"\"\"\n",
    "    Evaluate using ROUGE metric. This measures overlap of n-grams, word sequences, and word pairs.\n",
    "    \"\"\"\n",
    "    # Defining the ROUGE types we want to compute\n",
    "    rouge_types = ['rouge1', 'rouge2', 'rougeL']\n",
    "    \n",
    "    # Initialize the RougeScorer with the specified rouge_types\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_types)\n",
    "    \n",
    "    # Compute the ROUGE scores\n",
    "    scores = scorer.score(true_answer, predicted_answer)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(df, retriever, r2former):\n",
    "    \"\"\"\n",
    "    This function evaluates the R2AG model based on the dataset provided.\n",
    "    It calculates F1 score and ROUGE score for each example.\n",
    "    \"\"\"\n",
    "    f1_scores = []\n",
    "    rouge_scores = []\n",
    "    model_responses = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Step 1: Get query, true answer, and retrieve relevant documents\n",
    "        question = preprocess_text(row[\"question\"])  # Preprocess question\n",
    "        true_answer = preprocess_text(row[\"answer\"])  # Preprocess true answer\n",
    "        refined_embeddings, retrieved_docs = transform_retrievals(retriever, question, r2former)\n",
    "\n",
    "        # Step 2: Generate model response\n",
    "        model_response = generate_response(question, refined_embeddings, retrieved_docs)\n",
    "\n",
    "        # Step 3: Perform F1 and ROUGE evaluations\n",
    "        f1_pred, f1_true = f1_score_evaluation(model_response, true_answer)\n",
    "        rouge_result = rouge_evaluation(model_response, true_answer)\n",
    "\n",
    "        f1_scores.append(f1_pred)\n",
    "        rouge_scores.append(rouge_result['rouge1'].fmeasure)  # Using ROUGE-1 F1 score for simplicity\n",
    "        model_responses.append(model_response)\n",
    "\n",
    "    # Step 4: Calculate overall F1 and ROUGE scores\n",
    "    overall_f1 = f1_score(f1_scores, f1_scores)  # The F1 Score will be 1 if all predictions are correct\n",
    "    overall_rouge = sum(rouge_scores) / len(rouge_scores)  # Average ROUGE F1 score for all examples\n",
    "\n",
    "    print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
    "    print(f\"Overall ROUGE-1 F1 Score: {overall_rouge:.4f}\")\n",
    "\n",
    "    # Step 5: Create DataFrame for results\n",
    "    results = pd.DataFrame({\n",
    "        \"question\": df[\"question\"],\n",
    "        \"true_answer\": df[\"answer\"],\n",
    "        \"model_response\": model_responses,\n",
    "        \"f1_score\": f1_scores,\n",
    "        \"rouge1_f1_score\": rouge_scores\n",
    "    })\n",
    "\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
